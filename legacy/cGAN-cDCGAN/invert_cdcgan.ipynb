{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import make_new_folder, plot_norm_losses, save_input_args, \\\n",
    "sample_z, class_loss_fn, plot_losses, corrupt, prep_data, plot_log_losses # one_hot\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import binary_cross_entropy as bce\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from time import time\n",
    "\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1_1 = nn.ConvTranspose2d(100, d*2, 4, 1, 0)\n",
    "        self.deconv1_1_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv1_2 = nn.ConvTranspose2d(10, d*2, 4, 1, 0)\n",
    "        self.deconv1_2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input, label):\n",
    "        x = F.relu(self.deconv1_1_bn(self.deconv1_1(input)))\n",
    "        y = F.relu(self.deconv1_2_bn(self.deconv1_2(label)))\n",
    "        x = torch.cat([x, y], 1)\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.tanh(self.deconv4(x))\n",
    "        # x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        # x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "def find_batch_z(gen, x, nz, lr, exDir, maxEpochs=100, alpha=1e-6, batchNo=0):\n",
    "\n",
    "    #generator in eval mode\n",
    "    gen.eval()\n",
    "\n",
    "    #save the \"original\" images\n",
    "    save_image(x.data, join(exDir, 'original_batch'+str(batchNo)+'.png'), normalize=True, nrow=10)\n",
    "\n",
    "    #Assume the prior is Standard Normal\n",
    "    pdf = torch.distributions.Normal(0, 1)\n",
    "\n",
    "    Zinit = Variable(torch.randn(x.size(0), nz).view(-1, nz, 1, 1).cuda(), requires_grad=True)\n",
    "    Yinit = torch.zeros(x.size(0), 10)\n",
    "    fixed_y_ = torch.ones(x.size(0), 1)\n",
    "    Yinit.scatter_(1, fixed_y_.type(torch.LongTensor), 1)\n",
    "    Yinit = Yinit.view(-1, 10, 1, 1)\n",
    "    Yinit = Variable(Yinit.cuda(), requires_grad=False)\n",
    "\n",
    "    #optimizer\n",
    "    optZ = torch.optim.RMSprop([Zinit], lr=lr)\n",
    "\n",
    "    losses = {'rec': [], 'logProb': []}\n",
    "    for e in range(maxEpochs):\n",
    "\n",
    "        #reconstruction loss\n",
    "        xHAT = gen.forward(Zinit, Yinit)\n",
    "        recLoss = F.mse_loss(xHAT, x)\n",
    "\n",
    "        #loss to make sure z's are Guassian\n",
    "        logProb = pdf.log_prob(Zinit).mean(dim=1)  #each element of Z is independant, so likelihood is a sum of log of elements\n",
    "        loss = recLoss - (alpha * logProb.mean())\n",
    "        \n",
    "\n",
    "        optZ.zero_grad()\n",
    "        loss.backward()\n",
    "        optZ.step()\n",
    "\n",
    "        losses['rec'].append(recLoss.data)\n",
    "        losses['logProb'].append(logProb.mean().data)\n",
    "\n",
    "        if e%100==0:\n",
    "            print('[%d] loss: %0.5f, recLoss: %0.5f, regMean: %0.5f' % (e, loss.data, recLoss.data, logProb.mean().data))\n",
    "            # save_image(xHAT.data, join(exDir, 'rec'+str(e)+'.png'), normalize=True)\n",
    "\n",
    "        #plot training losses\n",
    "        if e>0:\n",
    "            plot_losses(losses, exDir, e+1)\n",
    "            #plot_norm_losses(losses, exDir, e+1)\n",
    "\n",
    "    #visualise the final output\n",
    "    xHAT = gen.forward(Zinit, Yinit)\n",
    "    save_image(xHAT.data, join(exDir, 'rec_batch'+str(batchNo)+'.png'), normalize=True, nrow=10)\n",
    "\n",
    "    return Zinit, recLoss.data, xHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "Outputs will be saved to: InversionExperiments_untilted\n",
      "Prepare data loaders...\n",
      "Setting cuda device\n",
      "params loaded\n",
      "Data loaders ready.\n",
      "[0] loss: 0.17246, recLoss: 0.15825, regMean: -1.42061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwu/miniconda3/envs/pytorch-py35/lib/python3.5/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/home/zwu/miniconda3/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/zwu/miniconda3/envs/pytorch-py35/lib/python3.5/site-packages/matplotlib/pyplot.py:513: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100] loss: 0.02143, recLoss: 0.00791, regMean: -1.35170\n",
      "[0] loss: 0.19403, recLoss: 0.17985, regMean: -1.41891\n",
      "[100] loss: 0.02314, recLoss: 0.00949, regMean: -1.36482\n",
      "[0] loss: 0.17711, recLoss: 0.16291, regMean: -1.42050\n",
      "[100] loss: 0.02348, recLoss: 0.00989, regMean: -1.35870\n",
      "[0] loss: 0.18917, recLoss: 0.17496, regMean: -1.42072\n",
      "[100] loss: 0.02319, recLoss: 0.00960, regMean: -1.35907\n",
      "[0] loss: 0.17182, recLoss: 0.15765, regMean: -1.41747\n",
      "[100] loss: 0.02094, recLoss: 0.00749, regMean: -1.34496\n",
      "[0] loss: 0.17878, recLoss: 0.16455, regMean: -1.42235\n",
      "[100] loss: 0.02021, recLoss: 0.00670, regMean: -1.35109\n",
      "[0] loss: 0.17033, recLoss: 0.15621, regMean: -1.41206\n",
      "[100] loss: 0.02158, recLoss: 0.00811, regMean: -1.34724\n",
      "[0] loss: 0.16644, recLoss: 0.15222, regMean: -1.42189\n",
      "[100] loss: 0.02007, recLoss: 0.00657, regMean: -1.35052\n",
      "allRec: (991, 1, 32, 32)\n",
      "allX: (991, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'untilted_1'\n",
    "batchSize = 128\n",
    "maxEpochs = 200\n",
    "nz = 100\n",
    "imSize = 64\n",
    "lr = 0.01\n",
    "fSize = 64\n",
    "alpha = 1e-2\n",
    "#Create new subfolder for saving results and training params\n",
    "exDir = 'InversionExperiments_untilted'\n",
    "try:\n",
    "    os.mkdir(exDir)\n",
    "except:\n",
    "    print('already exists')\n",
    "\n",
    "print('Outputs will be saved to:',exDir)\n",
    "\n",
    "im_size = 32\n",
    "\n",
    "print('Prepare data loaders...')\n",
    "transform = transforms.Compose([\n",
    "        transforms.Scale(im_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])    \n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=False, download=False, transform=transform),\n",
    "        batch_size=batchSize, shuffle=False)\n",
    "\n",
    "###### Create model and load parameters #####\n",
    "G = generator(128)\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "print('Setting cuda device')\n",
    "torch.cuda.set_device(0)\n",
    "G.cuda()\n",
    "G.load_state_dict(torch.load('MNIST_cDCGAN_results/data/MNIST_cDCGAN_generator_param.pkl'))\n",
    "print('params loaded')\n",
    "\n",
    "#testLoader = torch.utils.data.DataLoader(testDataset, batch_size=opts.batchSize, shuffle=False)\n",
    "print('Data loaders ready.')\n",
    "\n",
    "#Find each z individually for each x\n",
    "allRec = []\n",
    "allX = []\n",
    "sumLoss = 0\n",
    "for i, data in enumerate(testLoader):\n",
    "    x, y = prep_data(data, useCUDA=True)\n",
    "    z, recLoss, xRec = find_batch_z(gen=G, x=x, nz=100, lr=lr, exDir=exDir, maxEpochs=maxEpochs, alpha=alpha, batchNo=i)\n",
    "\n",
    "    allRec.append(xRec.cpu().data)\n",
    "    allX.append(x.cpu().data) #incase the loader shuffles samples\n",
    "\n",
    "allRec = np.concatenate(allRec)\n",
    "allX = np.concatenate(allX)\n",
    "print('allRec:', np.shape(allRec))\n",
    "print('allX:', np.shape(allX))\n",
    "\n",
    "\n",
    "mseLoss = np.mean((allRec - allX)**2, axis=(1,2,3))  # mean over colour channels and pixels\n",
    "np.save(join(exDir, 'mseLosses_per_sample.npy'), mseLoss)\n",
    "meanLoss = np.mean(mseLoss) # mean over samples\n",
    "stdLoss = np.std(mseLoss)  #std over samples\n",
    "\n",
    "f = open(join(exDir,'recError.txt'), 'w')\n",
    "f.write('mean loss %0.5f' % (meanLoss))\n",
    "f.write('std of loss %0.5f' % (stdLoss))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
